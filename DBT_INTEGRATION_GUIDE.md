# Netflix dbt Project Integration Guide

## ðŸ“‹ Table of Contents
- [Overview](#overview)
- [Architecture Flowchart](#architecture-flowchart)
- [Prerequisites](#prerequisites)
- [Integration Steps](#integration-steps)
- [Data Flow](#data-flow)
- [Results & Outputs](#results--outputs)
- [Project Structure](#project-structure)

---

## ðŸŽ¯ Overview

This project demonstrates a complete **modern data stack** implementation using:
- **AWS S3** â†’ Raw data storage
- **Snowflake** â†’ Cloud data warehouse
- **dbt (Data Build Tool)** â†’ Data transformation & modeling

**Purpose**: Transform raw Netflix movie data into analytics-ready models using SQL-based transformations with version control, testing, and documentation.

---

## ðŸ”„ Architecture Flowchart

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA PIPELINE FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAW DATA       â”‚
â”‚   (Local CSV)    â”‚
â”‚                  â”‚
â”‚ â€¢ movies.csv     â”‚
â”‚ â€¢ tags.csv       â”‚
â”‚ â€¢ links.csv      â”‚
â”‚ â€¢ genome-tags.csvâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Upload
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS S3 BUCKET  â”‚
â”‚                  â”‚
â”‚ netflix-dbt-data â”‚
â”‚   /raw-data/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ COPY INTO
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SNOWFLAKE DATA WAREHOUSE                         â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  RAW SCHEMA (MOVIELENS.RAW)                                    â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚  â€¢ RAW_MOVIES          â€¢ RAW_RATINGS                           â”‚ â”‚
â”‚  â”‚  â€¢ RAW_TAGS            â€¢ RAW_GENOME_SCORES                     â”‚ â”‚
â”‚  â”‚  â€¢ RAW_LINKS           â€¢ RAW_GENOME_TAGS                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                         â”‚
â”‚                             â”‚ dbt reads from (source)                 â”‚
â”‚                             â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DEV SCHEMA (MOVIELENS.DEV) - dbt Managed                      â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚ STAGING LAYER (Views)                                  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ src_movies      â€¢ src_ratings                 â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ src_tags        â€¢ src_genome_scores           â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ src_genome_tags â€¢ src_link                    â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚                                                 â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ Purpose: Basic cleaning & standardization      â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                          â”‚ dbt ref()                           â”‚ â”‚
â”‚  â”‚                          â–¼                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚ DIMENSIONAL LAYER (Tables)                             â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ dim_movies (with genre arrays)                â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ dim_users (unique users)                      â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ dim_genome_tags (tag labels)                  â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚                                                 â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ Purpose: Star schema dimensions                â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                          â”‚ dbt ref()                           â”‚ â”‚
â”‚  â”‚                          â–¼                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚ FACT LAYER (Tables/Incremental)                        â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ fct_ratings (INCREMENTAL)                     â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚   â†’ Timestamp-based incremental loading         â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ fct_genome_score                              â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚                                                 â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ Purpose: Fact tables with metrics               â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                          â”‚ dbt ref()                           â”‚ â”‚
â”‚  â”‚                          â–¼                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚ GOLD LAYER (Views - Analytics Ready)                   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ genre_ratings (avg by genre)                  â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ user_engagement (activity metrics)            â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ tag_relevance (tag analysis)                  â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ monthly_trends (time series)                  â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ top10_by_genre (rankings)                     â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ â€¢ movie_analysis (detailed stats)               â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚                                                 â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â”‚ Purpose: Business-ready analytics               â”‚   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                          â”‚                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚ MART LAYER (Tables)                                    â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ mart_movie_realeases (business-specific)             â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SNAPSHOTS SCHEMA (MOVIELENS.SNAPSHOTS)                        â”‚ â”‚
â”‚  â”‚  â€¢ snap_tags (SCD Type 2 - Historical tracking)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Query Results
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BI TOOLS /      â”‚
â”‚  ANALYSTS        â”‚
â”‚                  â”‚
â”‚ â€¢ Tableau        â”‚
â”‚ â€¢ PowerBI        â”‚
â”‚ â€¢ SQL Clients    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Œ Prerequisites

### 1. **Development Environment**
```bash
âœ… WSL2 or Linux environment
âœ… Python 3.8+ (we used 3.12.3)
âœ… pip (Python package manager)
âœ… Git for version control
```

### 2. **Cloud Services**
```bash
âœ… AWS Account
   - IAM user with S3 permissions
   - Access Key & Secret Key

âœ… Snowflake Account
   - Account identifier (e.g., abc12345.us-east-1)
   - Username & Password
   - ACCOUNTADMIN or similar role
```

### 3. **Required Tools**
```bash
âœ… AWS CLI (for S3 operations)
âœ… dbt-snowflake (for transformations)
âœ… Text editor (VS Code recommended)
```

---

## ðŸ› ï¸ Integration Steps

### **Phase 1: AWS S3 Setup**

#### Step 1.1: Install AWS CLI
```bash
sudo snap install aws-cli --classic
aws --version
```

#### Step 1.2: Configure AWS Credentials
```bash
aws configure
# Enter:
# - AWS Access Key ID
# - AWS Secret Access Key
# - Region: us-east-1
# - Output: json
```

#### Step 1.3: Create S3 Bucket & Upload Data
```bash
cd /home/huyng/netflix-dbt-project/netflix-dbt-project
./setup_aws_s3.sh
```

**What happens:**
- Creates S3 bucket: `netflix-dbt-data-YYYYMMDD`
- Enables versioning
- Uploads CSV files from `/data/` directory
- Generates IAM policy for Snowflake access

**Result:**
```
âœ… S3 Bucket created: s3://netflix-dbt-data-20251025/raw-data/
âœ… Files uploaded:
   - genome-tags.csv (16.6 KB)
   - links.csv (530.1 KB)
   - movies.csv (1.3 MB)
   - tags.csv (15.4 MB)
```

---

### **Phase 2: Snowflake Setup**

#### Step 2.1: Create Database Structure
Run in Snowflake SQL worksheet:
```sql
-- Create database and schemas
CREATE DATABASE MOVIELENS;
CREATE SCHEMA MOVIELENS.RAW;
CREATE SCHEMA MOVIELENS.DEV;
CREATE SCHEMA MOVIELENS.SNAPSHOTS;

-- Create warehouse
CREATE WAREHOUSE COMPUTE_WH 
WITH WAREHOUSE_SIZE='X-SMALL' 
AUTO_SUSPEND=300 
AUTO_RESUME=TRUE;
```

#### Step 2.2: Configure S3 Integration
```sql
-- Create storage integration
CREATE STORAGE INTEGRATION s3_netflix_integration
  TYPE = EXTERNAL_STAGE
  STORAGE_PROVIDER = 'S3'
  ENABLED = TRUE
  STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::YOUR_ACCOUNT:role/snowflake-s3-role'
  STORAGE_ALLOWED_LOCATIONS = ('s3://netflix-dbt-data-20251025/raw-data/');

-- Get Snowflake IAM User ARN (for AWS IAM trust policy)
DESC STORAGE INTEGRATION s3_netflix_integration;
```

#### Step 2.3: Configure AWS IAM Role
```bash
cd /home/huyng/netflix-dbt-project/netflix-dbt-project
./setup_iam_role.sh
# Enter Snowflake's IAM User ARN and External ID when prompted
```

**What happens:**
- Creates IAM role: `snowflake-s3-role`
- Configures trust relationship with Snowflake
- Attaches S3 read permissions

#### Step 2.4: Create Staging & Load Data
```sql
-- Create file format
CREATE FILE FORMAT csv_format
  TYPE='CSV'
  FIELD_DELIMITER=','
  SKIP_HEADER=1
  FIELD_OPTIONALLY_ENCLOSED_BY='"'
  TRIM_SPACE=TRUE;

-- Create external stage
CREATE STAGE s3_netflix_stage
  STORAGE_INTEGRATION = s3_netflix_integration
  URL = 's3://netflix-dbt-data-20251025/raw-data/'
  FILE_FORMAT = csv_format;

-- Verify connection
LIST @s3_netflix_stage;

-- Create raw tables
CREATE TABLE RAW.RAW_MOVIES (movieId INT, title STRING, genres STRING);
CREATE TABLE RAW.RAW_TAGS (userId INT, movieId INT, tag STRING, timestamp BIGINT);
CREATE TABLE RAW.RAW_LINKS (movieId INT, imdbId STRING, tmdbId STRING);
CREATE TABLE RAW.RAW_GENOME_TAGS (tagId INT, tag STRING);
CREATE TABLE RAW.RAW_RATINGS (userId INT, movieId INT, rating FLOAT, timestamp BIGINT);
CREATE TABLE RAW.RAW_GENOME_SCORES (movieId INT, tagId INT, relevance FLOAT);

-- Load data from S3
COPY INTO RAW.RAW_MOVIES FROM @s3_netflix_stage/movies.csv FILE_FORMAT=csv_format;
COPY INTO RAW.RAW_TAGS FROM @s3_netflix_stage/tags.csv FILE_FORMAT=csv_format;
COPY INTO RAW.RAW_LINKS FROM @s3_netflix_stage/links.csv FILE_FORMAT=csv_format;
COPY INTO RAW.RAW_GENOME_TAGS FROM @s3_netflix_stage/genome-tags.csv FILE_FORMAT=csv_format;
```

**Result:**
```
âœ… Raw tables created in MOVIELENS.RAW schema
âœ… Data loaded from S3 into Snowflake
âœ… Verified row counts for all tables
```

---

### **Phase 3: dbt Setup & Configuration**

#### Step 3.1: Install dbt
```bash
cd /home/huyng/netflix-dbt-project/netflix-dbt-project

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dbt-snowflake
pip install dbt-snowflake

# Verify installation
dbt --version
```

**Result:**
```
Core: 1.11.0-b3
Plugins:
  - snowflake: 1.10.2
```

#### Step 3.2: Configure dbt Profile
Create `~/.dbt/profiles.yml`:
```yaml
netflix:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: ORQFPMS-CE07071  # Your Snowflake account
      user: johnng305            # Your username
      password: ********         # Your password
      role: ACCOUNTADMIN
      database: MOVIELENS
      warehouse: COMPUTE_WH
      schema: DEV
      threads: 4
      client_session_keep_alive: False
```

#### Step 3.3: Test Connection
```bash
cd netflix
dbt debug
```

**Result:**
```
âœ… profiles.yml file [OK found and valid]
âœ… dbt_project.yml file [OK found and valid]
âœ… Connection test: [OK connection ok]
âœ… All checks passed!
```

---

### **Phase 4: dbt Execution**

#### Step 4.1: Install Dependencies
```bash
dbt deps
```

**What happens:**
- Installs `dbt_utils` package (v1.3.0)
- Used for surrogate key generation in snapshots

#### Step 4.2: Load Seed Data
```bash
dbt seed
```

**What happens:**
- Loads `seed_movie_release_dates.csv` into Snowflake
- Creates static reference table

**Result:**
```
âœ… seed_movie_release_dates [INSERT 10 rows]
```

#### Step 4.3: Run All Models
```bash
dbt run
```

**Execution Order (automatically determined by dbt):**
1. **Staging Layer** (6 views)
   - `src_movies`, `src_tags`, `src_ratings`, `src_genome_scores`, `src_genome_tags`, `src_link`

2. **Dimensional Layer** (3 tables)
   - `dim_movies` (with genre arrays)
   - `dim_users` (from ratings + tags)
   - `dim_genome_tags` (cleaned tag labels)

3. **Fact Layer** (2 tables)
   - `fct_ratings` (incremental - only new ratings)
   - `fct_genome_score` (relevance scores)

4. **Gold Layer** (7 views)
   - `genre_ratings`, `user_engagement`, `tag_relevance`
   - `monthly_trends`, `movie_analysis`, `top10_by_genre`
   - `release_trends`

5. **Mart Layer** (1 table)
   - `mart_movie_realeases` (business-specific)

**Result:**
```
âœ… Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
â±ï¸ Finished in 6.32 seconds
```

#### Step 4.4: Run Tests
```bash
dbt test
```

**What tests run:**
- **Schema tests** (from `models/schema.yml`):
  - `unique` checks (user_id, tag_id)
  - `not_null` checks (primary keys, required fields)
  - `relationships` checks (foreign key integrity)
  
- **Custom tests** (from `tests/` directory):
  - `relevant_score_test` (using custom macro)

**Result:**
```
âœ… Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
```

#### Step 4.5: Run Snapshots (Optional)
```bash
dbt snapshot
```

**What happens:**
- Creates SCD Type 2 tracking for `src_tags`
- Tracks historical changes with validity timestamps
- Limited to 100 rows for demo

#### Step 4.6: Generate Documentation
```bash
dbt docs generate
dbt docs serve --port 8080
```

**What's included:**
- Interactive lineage graph (DAG)
- Model descriptions & column definitions
- Test coverage visualization
- Source data documentation
- Compiled SQL code

**Result:**
```
âœ… Documentation available at http://localhost:8080
```

---

## ðŸ“Š Data Flow Details

### **1. Staging Layer**
```sql
-- Example: src_movies.sql
WITH raw_movies AS (
    SELECT * FROM MOVIELENS.RAW.RAW_MOVIES
)
SELECT
    movieId AS movie_id,
    title,
    genres
FROM raw_movies
```

**Purpose:**
- Clean field names (camelCase â†’ snake_case)
- Basic filtering (WHERE conditions)
- No business logic yet

**Materialization:** Views (no data storage, always fresh)

---

### **2. Dimensional Layer**
```sql
-- Example: dim_movies.sql
WITH src_movies AS (
    SELECT * FROM {{ ref('src_movies') }}
)
SELECT
    movie_id,
    INITCAP(TRIM(title)) AS movie_title,
    SPLIT(genres, '|') AS genre_array,  -- Convert to array
    genres
FROM src_movies
```

**Purpose:**
- Apply business logic (title formatting)
- Create derived fields (genre arrays)
- Build star schema dimensions

**Materialization:** Tables (faster queries, updated on each run)

---

### **3. Fact Layer**
```sql
-- Example: fct_ratings.sql (INCREMENTAL)
{{
    config(
        materialized='incremental',
        on_schema_change='fail'
    )
}}

WITH src_ratings AS (
    SELECT * FROM {{ ref('src_ratings') }}
)

SELECT
    user_id,
    movie_id,
    rating,
    rating_timestamp
FROM src_ratings
WHERE rating IS NOT NULL

{% if is_incremental() %}
    -- Only load new ratings
    AND rating_timestamp > (SELECT MAX(rating_timestamp) FROM {{ this }})
{% endif %}
```

**Purpose:**
- Store metrics & measurements
- Incremental loading for performance
- Timestamp-based change detection

**Materialization:** Table (incremental updates)

---

### **4. Gold Layer**
```sql
-- Example: genre_ratings.sql
SELECT
    g.value::string AS genre,
    AVG(r.rating) AS average_rating,
    COUNT(DISTINCT m.movie_id) AS total_movies
FROM {{ ref('fct_ratings') }} r
JOIN {{ ref('dim_movies') }} m 
    ON r.movie_id = m.movie_id,
    LATERAL FLATTEN(input => m.genre_array) g
GROUP BY genre
ORDER BY average_rating DESC
```

**Purpose:**
- Business-ready analytics
- Pre-aggregated metrics
- Optimized for BI tools

**Materialization:** Views (always current, no storage)

---

## ðŸŽ¯ Results & Outputs

### **1. Snowflake Objects Created**

```
MOVIELENS Database
â”œâ”€â”€ RAW Schema (6 tables)
â”‚   â”œâ”€â”€ RAW_MOVIES
â”‚   â”œâ”€â”€ RAW_TAGS
â”‚   â”œâ”€â”€ RAW_LINKS
â”‚   â”œâ”€â”€ RAW_GENOME_TAGS
â”‚   â”œâ”€â”€ RAW_RATINGS
â”‚   â””â”€â”€ RAW_GENOME_SCORES
â”‚
â”œâ”€â”€ DEV Schema (20 objects)
â”‚   â”œâ”€â”€ Staging Views (6)
â”‚   â”œâ”€â”€ Dimension Tables (3)
â”‚   â”œâ”€â”€ Fact Tables (2)
â”‚   â”œâ”€â”€ Gold Views (7)
â”‚   â”œâ”€â”€ Mart Tables (1)
â”‚   â””â”€â”€ Seed Tables (1)
â”‚
â””â”€â”€ SNAPSHOTS Schema
    â””â”€â”€ snap_tags (SCD Type 2)
```

### **2. dbt Artifacts Generated**

```
netflix/target/
â”œâ”€â”€ manifest.json       # Full project metadata
â”œâ”€â”€ catalog.json        # Column-level metadata
â”œâ”€â”€ run_results.json    # Execution results
â”œâ”€â”€ compiled/           # Compiled SQL (with refs resolved)
â””â”€â”€ run/               # Executed SQL statements
```

### **3. Key Metrics**

| Metric | Value |
|--------|-------|
| **Total Models** | 21 |
| **Data Tests** | 15 |
| **Sources** | 6 |
| **Snapshots** | 1 |
| **Seeds** | 1 |
| **Build Time** | ~6 seconds |
| **Test Time** | ~4 seconds |
| **Success Rate** | 100% |

---

## ðŸ“ Project Structure

```
netflix-dbt-project/
â”œâ”€â”€ data/                          # Raw CSV files
â”‚   â”œâ”€â”€ movies.csv
â”‚   â”œâ”€â”€ tags.csv
â”‚   â”œâ”€â”€ links.csv
â”‚   â””â”€â”€ genome-tags.csv
â”‚
â”œâ”€â”€ netflix/                       # dbt project root
â”‚   â”œâ”€â”€ dbt_project.yml           # Project configuration
â”‚   â”œâ”€â”€ packages.yml              # Package dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # SQL models
â”‚   â”‚   â”œâ”€â”€ sources.yml          # Source definitions
â”‚   â”‚   â”œâ”€â”€ schema.yml           # Model documentation & tests
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ staging/             # Staging layer
â”‚   â”‚   â”‚   â”œâ”€â”€ src_movies.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ src_tags.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ src_ratings.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ src_genome_scores.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ src_genome_tags.sql
â”‚   â”‚   â”‚   â””â”€â”€ src_link.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ dim/                 # Dimensions
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_movies.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_users.sql
â”‚   â”‚   â”‚   â””â”€â”€ dim_genome_tags.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ fct/                 # Facts
â”‚   â”‚   â”‚   â”œâ”€â”€ fct_ratings.sql (incremental)
â”‚   â”‚   â”‚   â”œâ”€â”€ fct_genome_score.sql
â”‚   â”‚   â”‚   â””â”€â”€ ep_movie_with_tags.sql (ephemeral)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ gold/                # Analytics
â”‚   â”‚   â”‚   â”œâ”€â”€ genre_ratings.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ user_engagement.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ tag_relevance.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ monthly_trends.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ movie_analysis.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ top10_by_genre.sql
â”‚   â”‚   â”‚   â””â”€â”€ release_trends.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ mart/                # Business marts
â”‚   â”‚       â””â”€â”€ mart_movie_realeases.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ seeds/                   # Static data
â”‚   â”‚   â””â”€â”€ seed_movie_release_dates.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ snapshots/               # SCD tracking
â”‚   â”‚   â””â”€â”€ snap_tags.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                   # Custom tests
â”‚   â”‚   â””â”€â”€ relevant_score_test.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ macros/                  # Reusable SQL
â”‚   â”‚   â””â”€â”€ no_nulls_in_columns.sql
â”‚   â”‚
â”‚   â””â”€â”€ analyses/                # Ad-hoc queries
â”‚       â””â”€â”€ movie_analysis.sql
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md  # AI agent guidance
â”‚
â”œâ”€â”€ setup_aws_s3.sh              # AWS automation script
â”œâ”€â”€ setup_iam_role.sh            # IAM role automation
â”œâ”€â”€ snowflake_setup.sql          # Snowflake SQL commands
â””â”€â”€ aws_iam_policy.json          # IAM policy document
```

---

## ðŸ”‘ Key Integration Features

### **1. Materialization Strategy**
```yaml
# dbt_project.yml
models:
  netflix:
    +materialized: view      # Default: views
    dim:
      +materialized: table   # Dimensions: tables
    fct:
      +materialized: table   # Facts: tables
```

### **2. Incremental Loading**
```sql
-- Only loads new data based on timestamp
{% if is_incremental() %}
    AND rating_timestamp > (SELECT MAX(rating_timestamp) FROM {{ this }})
{% endif %}
```

### **3. Testing Framework**
- **Built-in tests**: unique, not_null, relationships, accepted_values
- **Custom tests**: Using macros for reusable logic
- **Data quality**: Automated validation on each run

### **4. Documentation**
- **Auto-generated**: From code comments and schema.yml
- **Lineage graph**: Visual DAG of dependencies
- **Column-level**: Descriptions and data types

### **5. Version Control**
- Git for tracking changes
- Modular SQL files
- Reproducible builds

---

## ðŸš€ Ongoing Operations

### **Daily Operations**
```bash
# Activate environment
source .venv/bin/activate
cd netflix

# Run incremental updates
dbt run --select fct_ratings

# Run all models (fresh build)
dbt run

# Validate data quality
dbt test
```

### **Data Refresh**
```bash
# Full refresh of incremental models
dbt run --full-refresh --select fct_ratings

# Run specific model and dependencies
dbt run --select +dim_movies
```

### **Monitoring**
```bash
# Check run results
dbt run-operation list_models

# View compiled SQL
cat target/compiled/netflix/models/gold/genre_ratings.sql
```

---

## ðŸ“ˆ Benefits of This Integration

1. **Modularity**: Each model is a separate SQL file
2. **Testability**: Automated data quality checks
3. **Documentation**: Self-documenting with lineage
4. **Version Control**: Git-based workflow
5. **Performance**: Incremental loading, materialization options
6. **Reproducibility**: Consistent builds across environments
7. **Collaboration**: Clear dependencies and logic

---

## ðŸŽ“ Learning Resources

- **dbt Docs**: https://docs.getdbt.com/
- **Snowflake Docs**: https://docs.snowflake.com/
- **Project README**: `/README.md` (detailed tutorial)
- **Medium Article**: [Building an End-to-End Data Pipeline](https://medium.com/@codegnerdev/building-an-end-to-end-data-pipeline-with-dbt-snowflake-aws-the-netflix-data-analysis-project-bc26c1825e52)

---

**End of Integration Guide** ðŸŽ¬
